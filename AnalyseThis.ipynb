{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Training_Dataset.csv','rb') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    training_data=[]\n",
    "    for row in readCSV:\n",
    "        training_data.append(row)\n",
    "training_data=training_data[1:]\n",
    "training_data=np.asarray(training_data)\n",
    "n=training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catag=set(training_data[:,10])\n",
    "catag=list(catag)\n",
    "nc=len(catag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "data_scaled=[]\n",
    "supp=[]\n",
    "elite=[]\n",
    "credit=[]\n",
    "nsupp=[]\n",
    "nelite=[]\n",
    "ncredit=[]\n",
    "for i in range(0,nc):\n",
    "    data.append([])\n",
    "    data_scaled.append([])\n",
    "    supp.append([])\n",
    "    elite.append([])\n",
    "    credit.append([])\n",
    "    nsupp.append([])\n",
    "    nelite.append([])\n",
    "    ncredit.append([])\n",
    "i=0\n",
    "while i<n[0]:\n",
    "    j=0\n",
    "    while j<nc:\n",
    "        if training_data[i,10]==catag[j]:\n",
    "            data[j].append(training_data[i])\n",
    "        j+=1\n",
    "    i+=1\n",
    "\n",
    "data=np.asarray(data)\n",
    "    \n",
    "nd=np.empty(nc,dtype='int')\n",
    "for i in range(0,nc):\n",
    "    nd[i]=len(data[i])\n",
    "    supp[i]=np.zeros(nd[i],dtype='int')\n",
    "    elite[i]=np.zeros(nd[i],dtype='int')\n",
    "    credit[i]=np.zeros(nd[i],dtype='int')\n",
    "    nsupp[i]=np.zeros(nd[i],dtype='int')\n",
    "    nelite[i]=np.zeros(nd[i],dtype='int')\n",
    "    ncredit[i]=np.zeros(nd[i],dtype='int')\n",
    "    supp=np.asarray(supp)\n",
    "    elite=np.asarray(elite)\n",
    "    credit=np.asarray(credit)\n",
    "    nsupp=np.asarray(nsupp)\n",
    "    nelite=np.asarray(nelite)\n",
    "    ncredit=np.asarray(ncredit)\n",
    "    for j in range(0,nd[i]):\n",
    "        x1=data[i][j][0:10]\n",
    "        x2=data[i][j][11:-6]\n",
    "        supp[i][j]=data[i][j][-3]\n",
    "        elite[i][j]=data[i][j][-2]\n",
    "        credit[i][j]=data[i][j][-1]\n",
    "        nsupp[i][j]=data[i][j][-9]\n",
    "        nelite[i][j]=data[i][j][-8]\n",
    "        ncredit[i][j]=data[i][j][-7]\n",
    "        data[i][j]=np.append(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "for i in range(0,nc):\n",
    "    scaler.fit(data[i])\n",
    "    data_scaled[i]=scaler.transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_data=np.zeros([sum(nd),len(data_scaled[0][0])],dtype='float')\n",
    "class_data=np.zeros(sum(nd),dtype='int')\n",
    "count=0\n",
    "for i in range(0,nc):\n",
    "    for j in range(0,nd[i]):\n",
    "        for k in range(0,len(data_scaled[0][0])):\n",
    "            svm_data[count][k]=data_scaled[i][j][k]\n",
    "        if elite[i][j]==1:\n",
    "            class_data[count]=1\n",
    "        elif supp[i][j]==1:\n",
    "            class_data[count]=2\n",
    "        elif credit[i][j]==1:\n",
    "            class_data[count]=3\n",
    "        else:\n",
    "            class_data[count]=0\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_data_=[]\n",
    "class_data_=[]\n",
    "count=0\n",
    "for i in range(0,nc):\n",
    "    svm_data_.append([])\n",
    "    class_data_.append([])\n",
    "    for j in range(0,nd[i]):\n",
    "        svm_data_[i].append([])\n",
    "        class_data_[i].append([])\n",
    "        for k in range(0,len(data_scaled[0][0])):\n",
    "            svm_data_[i][j].append(data_scaled[i][j][k])\n",
    "        if elite[i][j]==1:\n",
    "            class_data_[i][j]=1\n",
    "        elif supp[i][j]==1:\n",
    "            class_data_[i][j]=2\n",
    "        elif credit[i][j]==1:\n",
    "            class_data_[i][j]=3\n",
    "        else:\n",
    "            class_data_[i][j]=0\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_data_=np.asarray(svm_data_)\n",
    "class_data_=np.asarray(class_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_svm=np.empty(nc,dtype='object')\n",
    "clf_dt=np.empty(nc,dtype='object')\n",
    "score=np.zeros(nc,dtype='float')\n",
    "score_svm=np.zeros(nc,dtype='float')\n",
    "for i in range(0,nc):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(svm_data_[i],class_data_[i])\n",
    "    clf_dt[i]=DecisionTreeClassifier().fit(X_train,y_train)\n",
    "    clf_svm[i]=SVC().fit(X_train,y_train)\n",
    "    score[i]=clf_dt[i].score(X_test,y_test)\n",
    "    score_svm[i]=clf_svm[i].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\graphlab\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\export.py:399: DeprecationWarning: out_file can be set to None starting from 0.18. This will be the default in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "export_graphviz(clf_dt[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Leaderboard_Dataset.csv','r') as csvfile1:\n",
    "    readCSV1 = csv.reader(csvfile1, delimiter=',')\n",
    "    testing_data=[]\n",
    "    for row1 in readCSV1:\n",
    "        testing_data.append(row1)\n",
    "testing_data=testing_data[1:]\n",
    "testing_data=np.asarray(testing_data)\n",
    "n=testing_data.shape\n",
    "cmkey=testing_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_catag=testing_data[:,11]\n",
    "test_catag_index=np.zeros(n[0],dtype='int')\n",
    "for j in range(0,n[0]):\n",
    "    for i in range(0,nc):\n",
    "        if test_catag[j]==catag[i]:\n",
    "            test_catag_index[j]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1=testing_data[:,1:11]\n",
    "x2=testing_data[:,12:]\n",
    "testing_data=np.append(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_data=np.empty([n[0],len(x1[0])+len(x2[0])],dtype='float')\n",
    "for i in range(0,n[0]):\n",
    "    for j in range(0,len(x1[0])):\n",
    "        testing_data[i][j]=x1[i][j]\n",
    "    for j in range(len(x1[0])+1,len(x2[0])):\n",
    "        testing_data[i][j]=x2[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "testing_data_scaled=np.empty(n[0],dtype='object')\n",
    "out=np.empty(n[0],dtype='object')\n",
    "out_svm=np.empty(n[0],dtype='object')\n",
    "for j in range(0,n[0]):\n",
    "    i=test_catag_index[j]\n",
    "    scaler.fit(data[i])\n",
    "    testing_data_scaled[j]=scaler.transform([testing_data[j]])\n",
    "    out[j]=[cmkey[j],clf_dt[i].predict(testing_data_scaled[j]),score[i]]\n",
    "    out_svm[j]=[cmkey[j],clf_svm[i].predict(testing_data_scaled[j]),score_svm[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_key=['Elite','Supp','Credit','none']\n",
    "out_array=np.zeros([n[0],len(out[0])],dtype='float')\n",
    "out_array_svm=np.zeros([n[0],len(out[0])],dtype='float')\n",
    "f=open('Leaderboard_output_dt.csv','w')\n",
    "f_svm=open('Leaderboard_output_svm.csv','w')\n",
    "for i in range(0,n[0]):\n",
    "    for j in range(0,len(out[0])):\n",
    "        out_array[i][j]=out[i][j]\n",
    "        out_array_svm[i][j]=out_svm[i][j]\n",
    "    f.write('%d,'%out_array[i][0])\n",
    "    f.write(class_key[int(out_array[i][1])])\n",
    "    f.write(',%f\\n'%out_array[i][2])\n",
    "    f_svm.write('%d,'%out_array_svm[i][0])\n",
    "    f_svm.write(class_key[int(out_array_svm[i][1])])\n",
    "    f_svm.write(',%f\\n'%out_array_svm[i][2])\n",
    "f.close()\n",
    "f_svm.close()\n",
    "np.savetxt(\"Leaderboard_output_dt_np.csv\",out_array,delimiter=\",\")\n",
    "np.savetxt(\"Leaderboard_output_svm_np.csv\",out_array,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# clf_e=np.empty(nc,dtype='object')\n",
    "# clf_s=np.empty(nc,dtype='object')\n",
    "# clf_c=np.empty(nc,dtype='object')\n",
    "# e=np.zeros(nc,dtype='int')\n",
    "# s=np.zeros(nc,dtype='int')\n",
    "# c=np.zeros(nc,dtype='int')\n",
    "# for i in range(0,nc):\n",
    "#     e[i]=s[i]=c[i]=0\n",
    "#     for j in range(0,nd[i]):\n",
    "#         if elite[i][j]==1:\n",
    "#             e[i]+=1\n",
    "#         if supp[i][j]==1:\n",
    "#             s[i]+=1\n",
    "#         if credit[i][j]==1:\n",
    "#             c[i]+=1\n",
    "#     if e[i]==0:\n",
    "#         data_scaled[i]=np.append(data_scaled[i],data_scaled[i][-1])\n",
    "#         elite[i]=np.append(elite[i],1)\n",
    "#         supp[i]=np.append(supp[i],0)\n",
    "#         credit[i]=np.append(credit[i],0)\n",
    "#     if s[i]==0:\n",
    "#         data_scaled[i]=np.append(data_scaled[i],data_scaled[i][-1])\n",
    "#         elite[i]=np.append(elite[i],0)\n",
    "#         supp[i]=np.append(supp[i],1)\n",
    "#         credit[i]=np.append(credit[i],0)\n",
    "#     if c[i]==0:\n",
    "#         data_scaled[i]=np.append(data_scaled[i],data_scaled[i][-1])\n",
    "#         elite[i]=np.append(elite[i],0)\n",
    "#         supp[i]=np.append(supp[i],0)\n",
    "#         credit[i]=np.append(credit[i],1)\n",
    "        \n",
    "#     clf_e[i]=LogisticRegression(C=100).fit(data_scaled[i],elite[i])\n",
    "#     clf_s[i]=LogisticRegression(C=100).fit(data_scaled[i],supp[i])\n",
    "#     clf_c[i]=LogisticRegression(C=100).fit(data_scaled[i],credit[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
